# iemt2

# What I have learned:
## I have learned quite a bit during this second repo exercise, but I must admit, some of it I still struggle with to understand. Here are my findings:

- I learned that BeautifulSoup is a library that you can use with Python for the purpose of web scraping. I was able to scrape some information from a website regarding the different regions in the Eastern Cape.
- I learned that the README.md file is used to document a LOT of information regarding a project. Some important information that can be found in it, is the project's name, a description of said project, requirements, usage instructions, and even a table of contents.
- The requirements.txt file is used to store the requirements (pip requirements, or packages) that the project needs to function properly.
- I used an extension, 'gitignore', by CodeZombie, to automatically create a .gitignore file that contains the requirement that the virtual environment must be ignored.
- I imported the 'beautifulsoup' and 'requests' modules to be able to complete the web scraping.
- I learned to use the entry point in a Python project. I have seen it used before, but this was my first time implementing it.
- I learned about a shebang, and I added the appropriate shebang at the very top of the Python file.
